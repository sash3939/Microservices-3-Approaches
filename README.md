# Домашнее задание к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

## Решение 1

Для обеспечения процесса разработки с учетом всех перечисленных требований можно рассмотреть следующую архитектуру, которая включает несколько облачных и локальных решений, интегрированных 
между собой
1. GitLab (облачная или self-hosted версия):
GitLab предоставляет все необходимые инструменты для организации процесса разработки, начиная с хранения исходного кода, заканчивая непрерывной интеграцией (CI) и доставкой (CD). Он поддерживает облачное развёртывание и может быть установлен локально при необходимости.

## Основные компоненты GitLab:
- GitLab SCM (Source Code Management) — система контроля версий, которая соответствует требованию о репозитории на каждый сервис. Вы можете создавать неограниченное количество репозиториев и управлять ими.

- GitLab CI/CD — интегрированная система CI/CD для автоматизации сборки, тестирования и развертывания. GitLab CI/CD поддерживает следующие функции:

  - Запуск сборок по событиям в системе контроля версий (например, push в ветку или открытие merge request).
  - Запуск сборок по кнопке с указанием параметров (возможны кастомные пайплайны, которые принимают параметры).
  - Возможность создания конфигурационных шаблонов для различных типов сборок с помощью .gitlab-ci.yml файла.
  - Настройки привязываются к каждой сборке через pipeline, позволяя задавать различные переменные окружения для разных сборок.

**Особенности**:

- Хранение секретных данных — в GitLab есть механизм хранения "секретов" (CI/CD variables), который позволяет безопасно управлять паролями, ключами доступа и другими конфиденциальными данными.

- Собственные докер-образы — возможность использовать собственные Docker-образы для сборок через GitLab Registry или сторонние контейнерные регистры (например, Docker Hub).

- Агенты сборки — возможность развернуть агентов (GitLab Runners) на собственных серверах или в облаке. GitLab поддерживает гибкость по размещению агентов для выполнения сборок.

- Параллельные сборки и тесты — GitLab CI/CD поддерживает параллельные задачи (stages и jobs), что позволяет одновременно запускать несколько сборок и тестов для ускорения цикла разработки.

**Пример сценария**:

>- Коммит в Git инициирует сборку и тестирование проекта.

>- При успешной сборке и тестировании, происходит развертывание на staging-среду.

>- Дополнительные шаги можно выполнять через кастомные скрипты в .gitlab-ci.yml файле (например, запуск миграций баз данных или отправка уведомлений).

2. Docker:

Для обеспечения изолированных и воспроизводимых окружений для сборок и тестов, Docker идеально подходит. Использование Docker позволит вам:

- Создавать собственные образы для сборки и тестирования.

- Изолировать зависимости каждой сборки в контейнерах, что минимизирует конфликты версий.

- Хранить образы в Docker Registry или GitLab Container Registry.

Взаимодействие с GitLab:

- GitLab CI/CD может использовать Docker-образы для выполнения сборок. Эти образы могут содержать необходимые зависимости и инструменты для сборки проекта.

- Можно использовать Docker Compose для локального тестирования нескольких микросервисов одновременно.

3. Kubernetes (по желанию):

Kubernetes может использоваться для управления инфраструктурой агентов сборки (GitLab Runners), а также для деплоя приложений. Вы можете:

- Развернуть GitLab Runners в Kubernetes, чтобы гибко масштабировать CI/CD.

- Использовать Helm-чарты для управления конфигурациями развертываний.

- Автоматизировать развёртывание сервисов в Kubernetes после успешных сборок.

4. HashiCorp Vault (для продвинутого хранения секретов):

Если вам требуется более сложное управление секретами, чем GitLab предоставляет, можно использовать HashiCorp Vault для безопасного хранения и динамического управления доступом к ключам и паролям. Vault можно интегрировать с GitLab через API для автоматической загрузки секретов в pipeline при выполнении сборок.

**Аргументы в пользу выбора**:

1. GitLab — это комплексное решение, которое покрывает практически все требования, начиная от системы контроля версий до CI/CD.

2. Docker — позволит легко управлять средами для сборки, тестов и развертывания, гарантируя повторяемость и изоляцию.

3. GitLab Runners — гибкие агенты для выполнения задач CI/CD, которые можно развернуть на любых серверах, включая облако и локальные ресурсы.

4. Поддержка параллельных сборок — обеспечит быстрое выполнение CI/CD пайплайнов с помощью нескольких параллельных задач.

5. Интеграция с Kubernetes и Vault — для масштабируемого и безопасного управления инфраструктурой и секретами, что особенно важно для крупных команд и сложных проектов.
Эта архитектура обеспечит высокую гибкость, безопасность и масштабируемость для вашего процесса разработки.

Другие варианты: Github+Jenkins+Vault

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

## Решение 2

Для сбора и анализа логов в микросервисной архитектуре, подходящим решением является стек ELK (Elasticsearch, Logstash, Kibana) или его упрощенный вариант EFK (Elasticsearch, Fluentd, Kibana). Этот стек удовлетворяет всем вашим требованиям и предоставляет масштабируемое решение для централизованного сбора, хранения и анализа логов.

1. ELK/EFK стек:

- Elasticsearch — высокопроизводительный движок для хранения и поиска данных. Он используется для индексирования и хранения логов, что позволяет эффективно выполнять поиск и фильтрацию по записям.

- Logstash/Fluentd — агент для сбора и доставки логов. Эти инструменты собирают логи из разных источников (stdout приложений, файловые логи, системные логи) и передают их в Elasticsearch.

- Kibana — мощный веб-интерфейс для визуализации данных, собранных в Elasticsearch. Он позволяет разработчикам выполнять поиск по логам, создавать фильтры и дашборды, а также сохранять и делиться результатами поиска.

Как компоненты работают вместе:

1. Сбор логов:

- Fluentd или Logstash могут быть настроены для сбора логов со всех микросервисов, используя их стандартные выходные потоки (stdout/stderr), что минимизирует требования к приложениям.

- Для микросервисов, запущенных в контейнерах (например, Docker или Kubernetes), можно настроить Fluentd для автоматического сбора логов из stdout контейнеров.

2. Доставка логов:

- Fluentd и Logstash поддерживают гарантированную доставку логов до центрального хранилища (Elasticsearch) за счёт использования буферизации и механизма подтверждений при отправке. Это гарантирует, что логи не будут потеряны в случае перебоев с сетью или временных проблем с доступом к Elasticsearch.

- Также можно настроить надёжные протоколы передачи данных (например, HTTP или TCP) с ретраями при ошибках.

3. Централизованное хранение:

- Elasticsearch принимает логи от Fluentd/Logstash, индексирует их и хранит в распределённой базе данных. Это обеспечивает быстрый доступ к логам даже при больших объёмах данных.

4. Поиск и фильтрация:

- Kibana предоставляет удобный интерфейс для поиска и фильтрации логов по различным полям (например, время, уровень логирования, текст ошибок). Вы можете задавать сложные запросы и фильтры через Lucene Query Language (LQL) или использовать визуальные инструменты Kibana.

- Также можно настроить автоматические алерты на основе логов, если, например, происходит много ошибок определённого типа.

5. Пользовательский интерфейс:

- Kibana предоставляет доступ к логам для разработчиков и других пользователей через веб-интерфейс. Пользователи могут создавать собственные запросы и дашборды, а также сохранять их для последующего использования.

- Возможность создания ссылок на сохраненные поиски и дашборды позволяет легко делиться результатами с коллегами. Например, можно создать дашборд для отслеживания ошибок и предоставить ссылку команде.

Расширенные возможности:

6. Шифрование и безопасность:

- Elasticsearch и Kibana могут быть настроены для использования TLS/SSL для обеспечения безопасной передачи данных.

- Права доступа можно настроить так, чтобы разные пользователи имели доступ к разным данным. Например, разработчики могут иметь доступ только к логам своих микросервисов.

Kubernetes и контейнеры:

- Для Kubernetes существует готовое решение с Fluentd или Fluent Bit (лёгкая версия Fluentd), которые могут собирать логи со всех контейнеров в кластере, что делает интеграцию с микросервисной архитектурой ещё проще.

- Инструменты вроде Filebeat или Fluent Bit также могут быть использованы для сбора логов с Docker контейнеров и отправки их в Elasticsearch.

**Обоснование выбора:**

1. Централизованный сбор логов — Fluentd или Logstash собирают логи со всех хостов, микросервисов и контейнеров, что делает процесс сбора логов простым и единообразным.

2. Гарантированная доставка — Fluentd/Logstash обеспечивают надёжную доставку логов с поддержкой буферизации и повторной отправки в случае сбоя.

3. Минимальные требования к приложениям — приложения могут просто записывать логи в stdout, что особенно удобно для микросервисов в контейнерах.

4. Масштабируемость — Elasticsearch отлично масштабируется для работы с большими объёмами данных, что позволяет обрабатывать огромные потоки логов.

5. Поиск и фильтрация — Elasticsearch и Kibana обеспечивают быстрый поиск и сложную фильтрацию по любым параметрам логов.

6. Пользовательский интерфейс — Kibana предоставляет гибкий интерфейс для поиска, фильтрации и визуализации данных, а также возможность сохранять и делиться запросами.

7. Интеграция с Kubernetes — существующие решения с Fluentd/Fluent Bit и Elasticsearch легко интегрируются в кластеры Kubernetes для автоматического сбора логов.
Эта архитектура представляет собой мощное и надёжное решение для сбора, анализа и визуализации логов в микросервисной архитектуре.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

## Решение 3

Для мониторинга состояния хостов и сервисов в микросервисной архитектуре можно предложить использование стека Prometheus + Grafana, который соответствует всем нашим требованиям.

1. Prometheus:

Prometheus — это мощная система мониторинга и сбора метрик с функциями алертинга, оптимизированная для микросервисной архитектуры. Она хорошо интегрируется с различными облачными и локальными решениями, а также с контейнеризированными сервисами.

Основные функции Prometheus:

- Сбор метрик со всех хостов и сервисов — Prometheus использует модель pull (запрос метрик через HTTP) для сбора данных с хостов и сервисов. На каждом хосте и сервисе должен быть запущен экспортёр метрик (например, Node Exporter для системных метрик).

- Сбор метрик состояния ресурсов хостов — с помощью Node Exporter, Prometheus собирает системные метрики хоста, включая:
  - Загрузка CPU;
  - Использование оперативной памяти (RAM);
  - Местоположение и использование жёстких дисков (HDD);
  - Сетевой трафик и активность.

- Сбор метрик ресурсов для каждого сервиса — каждый сервис должен экспортировать свои собственные метрики, включая:
  - Использование CPU, RAM, сетевых и дисковых ресурсов (в контейнерных средах это можно делать через cAdvisor, который собирает метрики с контейнеров).

- Сбор специфичных метрик для каждого сервиса — Prometheus поддерживает кастомные метрики, которые можно добавлять в код сервисов. Например, вы можете собирать метрики о времени отклика API, количестве обработанных запросов, количестве ошибок и т.д. Сервисы предоставляют эти метрики в формате, поддерживаемом Prometheus, обычно через HTTP endpoint /metrics.

Как Prometheus работает:

- Экспортёры на хостах и в контейнерах предоставляют системные и сервисные метрики.

- Prometheus делает регулярные запросы к экспортёрам для сбора метрик.

- Метрики хранятся в базе данных временных рядов (time series database) и доступны для запроса.

2. Grafana:

Grafana — это мощный инструмент для визуализации данных, собранных Prometheus, с поддержкой различных панелей и дашбордов.

Основные функции Grafana:

- Пользовательский интерфейс для создания запросов — Grafana позволяет разработчикам и администраторам выполнять запросы к данным в Prometheus с использованием языка запросов PromQL. Вы можете настраивать сложные запросы для анализа метрик.

- Настраиваемые панели для мониторинга состояния — Grafana поддерживает создание кастомных дашбордов, на которых можно размещать панели с различными метриками. Например:

  - Дашборды для системных метрик (CPU, RAM, HDD);
  - Дашборды для конкретных сервисов (нагрузка на сервис, количество запросов, метрики ошибок и т.д.).

- Алертинг — Grafana может генерировать уведомления на основе данных, собранных в Prometheus, например, если метрика достигает критического значения (например, превышение лимита по CPU или оперативной памяти).

3. cAdvisor и Node Exporter:

- Node Exporter — для сбора системных метрик с хостов. Это стандартный инструмент Prometheus для мониторинга состояния ресурсов хостов (CPU, RAM, диски, сеть и т.д.).

- cAdvisor — для сбора метрик с Docker-контейнеров (CPU, RAM, дисковое пространство и сетевые метрики). Это важно для мониторинга микросервисов, работающих в контейнерах.

Взаимодействие компонентов:

1. Prometheus собирает данные с хостов и сервисов через экспортёры.

2. Grafana визуализирует эти данные, позволяя строить дашборды и графики для мониторинга.

3. cAdvisor и Node Exporter обеспечивают системные метрики для контейнеров и хостов соответственно.

4. Разработчики могут использовать язык запросов PromQL для получения данных о состоянии системы и создания собственных аналитических панелей.

**Обоснование выбора**:

1. Prometheus — это современная система мониторинга, специально разработанная для микросервисных архитектур. Она легко интегрируется с контейнерами и сервисами через экспортёры и поддерживает сбор кастомных метрик.

2. Grafana — мощный и гибкий интерфейс для визуализации данных и создания дашбордов, что позволяет следить за состоянием системы в реальном времени.

3. Масштабируемость — решение легко масштабируется с увеличением числа сервисов и хостов.

4. Поддержка кастомных метрик — Prometheus позволяет гибко расширять список метрик для каждого микросервиса.

5. Интеграция с Kubernetes — Prometheus и Grafana легко интегрируются с Kubernetes, что делает их отличным выбором для облачных и контейнерных решений.

Эта архитектура позволяет эффективно собирать метрики, отслеживать состояние хостов и микросервисов, а также быстро реагировать на возникающие проблемы.


## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
